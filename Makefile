# Makefile for Stock Agent Trading System
# One-click commands for backtest, test, report, and more

.PHONY: help install test backtest report clean lint format docker-up docker-down

# Default target
.DEFAULT_GOAL := help

##@ General

help: ## Display this help message
	@awk 'BEGIN {FS = ":.*##"; printf "\nUsage:\n  make \033[36m<target>\033[0m\n"} /^[a-zA-Z_-]+:.*?##/ { printf "  \033[36m%-15s\033[0m %s\n", $$1, $$2 } /^##@/ { printf "\n\033[1m%s\033[0m\n", substr($$0, 5) } ' $(MAKEFILE_LIST)

##@ Installation

install: ## Install dependencies
	@echo "ðŸ“¦ Installing dependencies..."
	pip install -r requirements.txt
	@echo "âœ… Installation complete"

install-dev: ## Install development dependencies
	@echo "ðŸ“¦ Installing development dependencies..."
	pip install -r requirements.txt
	pip install pytest pytest-cov black flake8 mypy
	@echo "âœ… Development installation complete"

##@ Testing

test: ## Run all tests
	@echo "ðŸ§ª Running tests..."
	python -m pytest tests/ -v --tb=short
	@echo "âœ… Tests complete"

test-cov: ## Run tests with coverage
	@echo "ðŸ§ª Running tests with coverage..."
	python -m pytest tests/ -v --cov=. --cov-report=html --cov-report=term
	@echo "ðŸ“Š Coverage report: htmlcov/index.html"

test-contracts: ## Test signal contracts
	@echo "ðŸ“‹ Testing signal contracts..."
	python -m pytest tests/test_signal_validator.py -v
	python contracts/signal_validator.py
	@echo "âœ… Contract tests complete"

test-backtest: ## Test backtest harness
	@echo "ðŸŽ¯ Testing backtest harness..."
	python -m pytest tests/test_backtester.py -v
	@echo "âœ… Backtest tests complete"

##@ Backtesting

backtest: ## Run backtest (default config)
	@echo "ðŸš€ Running backtest..."
	python scripts/run_backtest.py
	@echo "âœ… Backtest complete - Check backtest_results/"

backtest-quick: ## Run quick backtest (3 months, 3 symbols)
	@echo "âš¡ Running quick backtest..."
	python scripts/run_backtest.py --symbols AAPL,MSFT,GOOGL --start 2023-10-01 --end 2023-12-31
	@echo "âœ… Quick backtest complete"

backtest-full: ## Run full backtest (1 year, 10 symbols)
	@echo "ðŸ”¥ Running full backtest..."
	python scripts/run_backtest.py --symbols AAPL,MSFT,GOOGL,AMZN,META,TSLA,NVDA,JPM,V,JNJ --start 2023-01-01 --end 2023-12-31
	@echo "âœ… Full backtest complete"

backtest-validate: ## Run backtest with signal validation enabled
	@echo "âœ… Running backtest with signal validation..."
	python scripts/run_backtest.py --validate-signals
	@echo "âœ… Validated backtest complete"

##@ Reporting

report: ## Generate backtest report (latest results)
	@echo "ðŸ“Š Generating backtest report..."
	python scripts/generate_report.py
	@echo "âœ… Report generated - Check backtest_results/"

report-html: ## Generate HTML report
	@echo "ðŸŒ Generating HTML report..."
	python scripts/generate_report.py --format html
	@echo "âœ… HTML report generated"

report-pdf: ## Generate PDF report
	@echo "ðŸ“„ Generating PDF report..."
	python scripts/generate_report.py --format pdf
	@echo "âœ… PDF report generated"

##@ Training

##@ SFT Training

train-news-agent: ## Train News Agent (SFT)
	@echo "ðŸ“° Training News Agent..."
	python scripts/train_agent_sft.py \
		--agent news_agent \
		--dataset data/datasets/sft_v1 \
		--output models/sft/news_agent_v1.0.0
	@echo "âœ… News Agent training complete"

train-technical-agent: ## Train Technical Agent (SFT)
	@echo "ðŸ“Š Training Technical Agent..."
	python scripts/train_agent_sft.py \
		--agent technical_agent \
		--dataset data/datasets/sft_v1 \
		--output models/sft/technical_agent_v1.0.0
	@echo "âœ… Technical Agent training complete"

train-fundamental-agent: ## Train Fundamental Agent (SFT)
	@echo "ðŸ’° Training Fundamental Agent..."
	python scripts/train_agent_sft.py \
		--agent fundamental_agent \
		--dataset data/datasets/sft_v1 \
		--output models/sft/fundamental_agent_v1.0.0
	@echo "âœ… Fundamental Agent training complete"

train-all-agents: ## Train all three agents (News, Technical, Fundamental)
	@echo "ðŸš€ Training all agents..."
	python scripts/train_agent_sft.py \
		--agent all \
		--dataset data/datasets/sft_v1 \
		--output-dir models/sft
	@echo "âœ… All agents training complete"

train-quick-test: ## Quick test training (1 epoch, 100 samples)
	@echo "âš¡ Quick test training..."
	python scripts/train_agent_sft.py \
		--agent news_agent \
		--dataset data/datasets/sft_v1 \
		--output models/sft/news_agent_test \
		--preset quick_test
	@echo "âœ… Quick test complete"

train-production: ## Production training with optimized settings
	@echo "ðŸ­ Production training..."
	python scripts/train_agent_sft.py \
		--agent all \
		--dataset data/datasets/sft_v1 \
		--output-dir models/sft \
		--preset production
	@echo "âœ… Production training complete"

##@ Model Registry

models-list: ## List all registered models
	@echo "ðŸ“‹ Listing registered models..."
	python training/sft/model_registry.py --list

models-best: ## Show best model for agent (usage: make models-best AGENT=news_agent)
	@echo "ðŸ† Best model for $(or $(AGENT),news_agent)..."
	python training/sft/model_registry.py --best --agent $(or $(AGENT),news_agent) --metric eval_loss

models-promote: ## Promote model to production (usage: make models-promote MODEL_ID=xxx)
	@echo "â¬†ï¸  Promoting model $(MODEL_ID) to production..."
	python training/sft/model_registry.py --promote $(MODEL_ID) --to-stage production
	@echo "âœ… Model promoted"

##@ Eval Gates & Regression Guards

eval-model: ## Evaluate model on holdout dataset (usage: make eval-model MODEL=xxx DATASET=xxx)
	@echo "ðŸ“Š Evaluating model on holdout dataset..."
	python training/sft/eval_gates.py \
		--model $(MODEL) \
		--dataset $(DATASET)
	@echo "âœ… Evaluation complete"

eval-with-drift: ## Evaluate with drift detection (usage: make eval-with-drift MODEL=xxx DATASET=xxx BASELINE='{"eval_loss":0.45}')
	@echo "ðŸ“Š Evaluating with drift detection..."
	python training/sft/eval_gates.py \
		--model $(MODEL) \
		--dataset $(DATASET) \
		--baseline-metrics '$(BASELINE)' \
		--drift-threshold 5.0
	@echo "âœ… Evaluation complete"

eval-history: ## View evaluation history
	@echo "ðŸ“œ Evaluation history:"
	python training/sft/eval_gates.py --history --limit 20

regression-test: ## Run regression test (usage: make regression-test BASELINE=xxx CANDIDATE=xxx)
	@echo "ðŸ” Running regression test..."
	python training/sft/regression_guards.py \
		--baseline $(BASELINE) \
		--candidate $(CANDIDATE) \
		--metrics eval_loss eval_accuracy eval_f1
	@echo "âœ… Regression test complete"

regression-test-holdout: ## Regression test with holdout (usage: make regression-test-holdout BASELINE_PATH=xxx CANDIDATE_PATH=xxx HOLDOUT=xxx)
	@echo "ðŸ” Running regression test with holdout re-evaluation..."
	python training/sft/regression_guards.py \
		--baseline-path $(BASELINE_PATH) \
		--candidate-path $(CANDIDATE_PATH) \
		--holdout $(HOLDOUT) \
		--metrics eval_loss eval_accuracy eval_f1
	@echo "âœ… Regression test complete"

regression-history: ## View regression test history
	@echo "ðŸ“œ Regression test history:"
	python training/sft/regression_guards.py --history --limit 20

regression-override: ## Override blocked model (usage: make regression-override TEST_ID=xxx REASON="explanation")
	@echo "âš ï¸  Applying override to test $(TEST_ID)..."
	python training/sft/regression_guards.py \
		--override $(TEST_ID) \
		--reason "$(REASON)"
	@echo "âœ… Override applied"

##@ RL Training

train-rl: ## Train RL model for strategist
	@echo "ðŸŽ® Training RL model..."
	python scripts/train_rl.py
	@echo "âœ… RL training complete"

##@ Data Synthesis

synthesize-sft: ## Synthesize SFT dataset (judge-approved, chat format)
	@echo "ðŸ”„ Synthesizing SFT dataset..."
	python scripts/synthesize_dataset.py --preset sft_v1
	@echo "âœ… SFT dataset synthesized"

synthesize-preference: ## Synthesize preference learning dataset (contrastive pairs)
	@echo "ðŸ”„ Synthesizing preference learning dataset..."
	python scripts/synthesize_dataset.py --preset preference_v1
	@echo "âœ… Preference dataset synthesized"

synthesize-rl: ## Synthesize RL training dataset (full spectrum)
	@echo "ðŸ”„ Synthesizing RL dataset..."
	python scripts/synthesize_dataset.py --preset rl_v1
	@echo "âœ… RL dataset synthesized"

synthesize-eval: ## Synthesize evaluation benchmark (gold standard)
	@echo "ðŸ”„ Synthesizing evaluation benchmark..."
	python scripts/synthesize_dataset.py --preset eval_benchmark
	@echo "âœ… Evaluation benchmark synthesized"

synthesize-custom: ## Synthesize custom dataset (specify --strategy, --format, etc.)
	@echo "ðŸ”„ Synthesizing custom dataset..."
	@echo "Usage: make synthesize-custom STRATEGY=judge_approved FORMAT=chat MIN_REWARD=0.5"
	python scripts/synthesize_dataset.py \
		--strategy $(or $(STRATEGY),judge_approved) \
		--format $(or $(FORMAT),chat) \
		--min-reward $(or $(MIN_REWARD),0.0)
	@echo "âœ… Custom dataset synthesized"

judge-filter: ## Apply judge filtering to experience store
	@echo "âš–ï¸  Applying judge filter to experiences..."
	python training/data_synthesis/judge_filter.py --storage-dir data/experiences --min-score 6.0
	@echo "âœ… Judge filtering complete"

experience-stats: ## Show experience store statistics
	@echo "ðŸ“Š Experience Store Statistics:"
	python training/data_synthesis/experience_store.py --storage-dir data/experiences --stats

experience-query: ## Query experiences (usage: make experience-query SYMBOL=AAPL MIN_REWARD=0.5)
	@echo "ðŸ” Querying experiences..."
	python training/data_synthesis/experience_store.py \
		--storage-dir data/experiences \
		--query \
		$(if $(SYMBOL),--symbol $(SYMBOL),) \
		$(if $(MIN_REWARD),--min-reward $(MIN_REWARD),) \
		$(if $(JUDGE_ONLY),--judge-approved-only,)
	@echo "âœ… Query complete"

##@ Code Quality

lint: ## Run linters
	@echo "ðŸ” Running linters..."
	flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
	flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
	@echo "âœ… Linting complete"

format: ## Format code with black
	@echo "ðŸŽ¨ Formatting code..."
	black . --line-length 100
	@echo "âœ… Code formatted"

type-check: ## Run type checker
	@echo "ðŸ”Ž Running type checker..."
	mypy . --ignore-missing-imports
	@echo "âœ… Type checking complete"

##@ Docker

docker-up: ## Start all services with Docker Compose
	@echo "ðŸ³ Starting Docker services..."
	docker compose up -d
	@echo "âœ… Services started"
	@echo "  API: http://localhost:8000"
	@echo "  Grafana: http://localhost:3000"
	@echo "  Prometheus: http://localhost:9090"

docker-down: ## Stop all Docker services
	@echo "ðŸ›‘ Stopping Docker services..."
	docker compose down
	@echo "âœ… Services stopped"

docker-logs: ## View Docker logs
	docker compose logs -f

docker-build: ## Build Docker images
	@echo "ðŸ”¨ Building Docker images..."
	docker compose build
	@echo "âœ… Build complete"

docker-backtest: ## Run backtest in Docker
	@echo "ðŸ³ Running backtest in Docker..."
	docker compose run --rm api python scripts/run_backtest.py
	@echo "âœ… Docker backtest complete"

##@ API

api-start: ## Start FastAPI server (development)
	@echo "ðŸš€ Starting API server..."
	uvicorn api.server:app --reload --host 0.0.0.0 --port 8000

api-test: ## Test API endpoints
	@echo "ðŸ§ª Testing API endpoints..."
	python scripts/test_api.py
	@echo "âœ… API tests complete"

##@ Database

db-init: ## Initialize PostgreSQL database
	@echo "ðŸ—„ï¸  Initializing database..."
	python scripts/init_database.py
	@echo "âœ… Database initialized"

db-migrate: ## Run database migrations
	@echo "ðŸ”„ Running database migrations..."
	python scripts/migrate_database.py
	@echo "âœ… Migrations complete"

db-backup: ## Backup database
	@echo "ðŸ’¾ Backing up database..."
	python scripts/backup_database.py
	@echo "âœ… Backup complete"

##@ Validation

validate-signals: ## Validate all signal examples
	@echo "âœ… Validating signal examples..."
	python -c "from contracts.signal_validator import validate_signal_file; \
		print('Testing valid signal...'); \
		is_valid, errors = validate_signal_file('contracts/examples/valid_buy_signal.json'); \
		print(f'Valid: {is_valid}'); \
		print('\nTesting invalid signal...'); \
		is_valid, errors = validate_signal_file('contracts/examples/invalid_signal.json', strict=False); \
		print(f'Valid: {is_valid}, Errors: {len(errors)}')"
	@echo "âœ… Signal validation complete"

validate-config: ## Validate system configuration
	@echo "âš™ï¸  Validating configuration..."
	python scripts/validate_config.py
	@echo "âœ… Configuration valid"

##@ Cleanup

clean: ## Clean temporary files and caches
	@echo "ðŸ§¹ Cleaning temporary files..."
	find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
	find . -type d -name "*.egg-info" -exec rm -rf {} + 2>/dev/null || true
	find . -type d -name ".pytest_cache" -exec rm -rf {} + 2>/dev/null || true
	find . -type d -name ".mypy_cache" -exec rm -rf {} + 2>/dev/null || true
	find . -type f -name "*.pyc" -delete 2>/dev/null || true
	find . -type f -name "*.pyo" -delete 2>/dev/null || true
	rm -rf htmlcov/ .coverage 2>/dev/null || true
	@echo "âœ… Cleanup complete"

clean-data: ## Clean generated data (backtest results, logs)
	@echo "ðŸ—‘ï¸  Cleaning generated data..."
	rm -rf backtest_results/*.json logs/*.log 2>/dev/null || true
	@echo "âš ï¸  Data cleaned"

clean-all: clean clean-data ## Clean everything

##@ Development

dev-setup: install-dev validate-config ## Setup development environment
	@echo "ðŸŽ‰ Development environment ready!"

dev-check: lint type-check test ## Run all development checks
	@echo "âœ… All checks passed!"

ci: lint type-check test backtest-quick ## Run CI pipeline
	@echo "âœ… CI pipeline complete"

##@ Production

prod-deploy: ## Deploy to production (with checks)
	@echo "ðŸš€ Deploying to production..."
	@make lint
	@make type-check
	@make test
	@make docker-build
	@make docker-up
	@echo "âœ… Production deployment complete"

prod-rollback: ## Rollback production deployment
	@echo "âª Rolling back production..."
	docker compose down
	git checkout main
	@make docker-build
	@make docker-up
	@echo "âœ… Rollback complete"

##@ Monitoring

logs: ## View application logs
	@echo "ðŸ“œ Viewing logs..."
	tail -f logs/app.log

logs-error: ## View error logs only
	@echo "âŒ Viewing error logs..."
	grep -i error logs/app.log | tail -100

monitor: ## Start monitoring dashboard
	@echo "ðŸ“Š Opening monitoring dashboard..."
	@echo "Grafana: http://localhost:3000 (admin/admin)"
	@echo "Prometheus: http://localhost:9090"

##@ Benchmarks

benchmark: ## Run performance benchmarks
	@echo "âš¡ Running benchmarks..."
	python scripts/benchmark.py
	@echo "âœ… Benchmarks complete"

benchmark-backtest: ## Benchmark backtest performance
	@echo "âš¡ Benchmarking backtest..."
	time make backtest-quick
	@echo "âœ… Backtest benchmark complete"

##@ Acceptance Tests (Phase A0)

acceptance-test: ## Run Phase A0 acceptance tests
	@echo "âœ… Running Phase A0 acceptance tests..."
	@echo "\n1. Testing Signal Contract..."
	@make validate-signals
	@echo "\n2. Testing Backtest Determinism..."
	python tests/acceptance/test_deterministic_backtest.py
	@echo "\n3. Testing Survivorship Bias Guard..."
	python tests/acceptance/test_survivorship_bias.py
	@echo "\n4. Testing Corporate Actions..."
	python tests/acceptance/test_corporate_actions.py
	@echo "\nâœ… All acceptance tests passed!"

acceptance-test-quick: validate-signals ## Quick acceptance test (contracts only)
	@echo "âœ… Quick acceptance test complete"

acceptance-test-sft: ## Run SFT training pipeline acceptance tests (Tasks #17-20)
	@echo "âœ… Running SFT training pipeline acceptance tests..."
	@echo "\n1. Testing SFT Training..."
	python tests/acceptance/test_sft_training.py
	@echo "\n2. Testing Eval Gates & Regression Guards..."
	python tests/acceptance/test_sft_pipeline_complete.py
	@echo "\nâœ… All SFT tests passed!"

##@ Documentation

docs: ## Generate documentation
	@echo "ðŸ“š Generating documentation..."
	python scripts/generate_docs.py
	@echo "âœ… Documentation generated"

docs-serve: ## Serve documentation locally
	@echo "ðŸŒ Serving documentation at http://localhost:8080"
	python -m http.server 8080 -d docs/

##@ Version

version: ## Show current version
	@echo "ðŸ“Œ Stock Agent Trading System"
	@python -c "import json; print('Version:', json.load(open('package.json'))['version'])" 2>/dev/null || echo "Version: 1.0.0"

##@ Quick Commands

all: install test backtest report ## Run complete workflow
	@echo "ðŸŽ‰ Complete workflow finished!"

quick: backtest-quick report ## Quick workflow (3 months)
	@echo "âš¡ Quick workflow complete!"

full: backtest-full report ## Full workflow (1 year)
	@echo "ðŸ”¥ Full workflow complete!"
