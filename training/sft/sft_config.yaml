# SFT Training Configuration
# Supervised Fine-Tuning for Junior Agents (News, Technical, Fundamental)

# ============================================================================
# Model Configuration
# ============================================================================

models:
  # Base models for fine-tuning
  base_models:
    llama3_8b:
      model_name: "meta-llama/Meta-Llama-3-8B"
      tokenizer_name: "meta-llama/Meta-Llama-3-8B"
      context_length: 8192
      recommended_for: "General purpose, balanced performance"

    llama3_70b:
      model_name: "meta-llama/Meta-Llama-3-70B"
      tokenizer_name: "meta-llama/Meta-Llama-3-70B"
      context_length: 8192
      recommended_for: "High quality, resource intensive"

    mistral_7b:
      model_name: "mistralai/Mistral-7B-v0.1"
      tokenizer_name: "mistralai/Mistral-7B-v0.1"
      context_length: 8192
      recommended_for: "Fast inference, good quality"

    gemma_7b:
      model_name: "google/gemma-7b"
      tokenizer_name: "google/gemma-7b"
      context_length: 8192
      recommended_for: "Good quality, free license"

    phi3_mini:
      model_name: "microsoft/Phi-3-mini-4k-instruct"
      tokenizer_name: "microsoft/Phi-3-mini-4k-instruct"
      context_length: 4096
      recommended_for: "Small model, fast training"

  # Default model per agent
  agent_defaults:
    news_agent: "mistral_7b"       # Fast, good at text understanding
    technical_agent: "llama3_8b"   # Balanced for numerical reasoning
    fundamental_agent: "llama3_8b" # Balanced for analysis

# ============================================================================
# LoRA/QLoRA Configuration
# ============================================================================

lora:
  # LoRA parameters
  r: 16                    # Rank (4, 8, 16, 32, 64)
  lora_alpha: 32           # Alpha (typically 2*r)
  lora_dropout: 0.05       # Dropout probability
  bias: "none"             # Bias type: "none", "all", "lora_only"
  task_type: "CAUSAL_LM"   # Task type

  # Target modules (transformer layers to apply LoRA)
  target_modules:
    llama: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
    mistral: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
    gemma: ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
    phi: ["qkv_proj", "o_proj", "gate_up_proj", "down_proj"]

  # QLoRA-specific (4-bit quantization)
  use_qlora: true
  bnb_4bit_compute_dtype: "bfloat16"  # float16, bfloat16
  bnb_4bit_quant_type: "nf4"          # nf4, fp4
  bnb_4bit_use_double_quant: true

# ============================================================================
# Training Hyperparameters
# ============================================================================

training:
  # Basic settings
  num_epochs: 3
  per_device_train_batch_size: 4
  per_device_eval_batch_size: 4
  gradient_accumulation_steps: 4   # Effective batch size = 4 * 4 = 16

  # Optimizer
  optimizer: "adamw_torch"
  learning_rate: 2.0e-4
  weight_decay: 0.01
  adam_beta1: 0.9
  adam_beta2: 0.999
  adam_epsilon: 1.0e-8
  max_grad_norm: 1.0

  # Learning rate schedule
  lr_scheduler_type: "cosine"        # linear, cosine, polynomial
  warmup_ratio: 0.03                 # 3% of total steps
  warmup_steps: null                 # If set, overrides warmup_ratio

  # Mixed precision
  fp16: false
  bf16: true                         # Better for modern GPUs (A100, H100)

  # Gradient checkpointing
  gradient_checkpointing: true       # Save memory at cost of speed

  # Logging
  logging_steps: 10
  logging_first_step: true
  logging_strategy: "steps"          # steps, epoch

  # Evaluation
  evaluation_strategy: "steps"       # steps, epoch, no
  eval_steps: 100
  eval_accumulation_steps: 4

  # Checkpointing
  save_strategy: "steps"             # steps, epoch, no
  save_steps: 500
  save_total_limit: 3                # Keep only last 3 checkpoints
  load_best_model_at_end: true
  metric_for_best_model: "eval_loss"
  greater_is_better: false

  # Early stopping
  early_stopping_patience: 3
  early_stopping_threshold: 0.001

  # Reproducibility
  seed: 42
  data_seed: 42

# ============================================================================
# Dataset Configuration
# ============================================================================

dataset:
  # Data paths
  data_dir: "data/datasets"
  train_file: "train.jsonl"
  val_file: "val.jsonl"
  test_file: "test.jsonl"

  # Data format
  input_format: "chat"               # chat, prompt_completion, instruction
  max_seq_length: 2048               # Maximum sequence length

  # Data preprocessing
  preprocessing:
    remove_duplicates: true
    shuffle_train: true
    truncation_strategy: "longest_first"  # longest_first, only_first, only_second

  # Data augmentation
  augmentation:
    enabled: false
    techniques: []

  # Streaming (for large datasets)
  streaming: false

# ============================================================================
# Agent-Specific Configurations
# ============================================================================

agents:
  news_agent:
    model_base: "mistral_7b"
    task_description: "Analyze news sentiment and extract key events for stock trading signals"

    # Agent-specific hyperparameters
    training_overrides:
      learning_rate: 2.0e-4
      num_epochs: 3
      per_device_train_batch_size: 4

    # Input/Output format
    input_fields: ["symbol", "news_articles", "sentiment_sources"]
    output_fields: ["sentiment_score", "confidence", "key_events", "reasoning"]

    # Evaluation metrics
    metrics: ["accuracy", "f1", "mae"]  # For sentiment classification

  technical_agent:
    model_base: "llama3_8b"
    task_description: "Analyze technical indicators and chart patterns for trading signals"

    training_overrides:
      learning_rate: 1.5e-4
      num_epochs: 3
      per_device_train_batch_size: 4

    input_fields: ["symbol", "price_data", "indicators"]
    output_fields: ["signal", "signal_strength", "support_levels", "resistance_levels", "reasoning"]

    metrics: ["accuracy", "f1", "mse"]  # For signal classification + numerical prediction

  fundamental_agent:
    model_base: "llama3_8b"
    task_description: "Analyze financial statements and fundamentals for valuation"

    training_overrides:
      learning_rate: 1.5e-4
      num_epochs: 3
      per_device_train_batch_size: 4

    input_fields: ["symbol", "financial_statements", "metrics"]
    output_fields: ["valuation", "financial_health_score", "growth_score", "reasoning"]

    metrics: ["accuracy", "f1", "mse"]

# ============================================================================
# Model Registry & Versioning
# ============================================================================

registry:
  # Model versioning
  versioning_scheme: "semantic"      # semantic (1.0.0) or timestamp (20240115_120000)
  auto_increment: true

  # Model storage
  models_dir: "models/sft"
  registry_db: "models/registry.db"  # SQLite database for tracking

  # Metadata tracking
  track_hyperparameters: true
  track_dataset_version: true
  track_git_commit: true
  track_training_metrics: true

  # Model naming
  naming_pattern: "{agent}_{model_base}_{version}"  # e.g., news_agent_mistral_7b_v1.0.0

# ============================================================================
# Evaluation Gates
# ============================================================================

eval_gates:
  # Minimum performance thresholds
  min_eval_loss: null                # null = no threshold
  min_eval_accuracy: 0.70            # 70% accuracy
  min_eval_f1: 0.65                  # 65% F1 score

  # Regression testing (new model must be >= old model)
  regression_testing:
    enabled: true
    baseline_model: null             # Path to baseline model (null = no regression check)
    metrics_to_compare: ["eval_loss", "eval_accuracy", "eval_f1"]
    tolerance: 0.02                  # Allow 2% degradation

  # Validation on holdout set
  holdout_validation:
    enabled: true
    holdout_dataset: "data/datasets/eval_benchmark/test.jsonl"
    min_holdout_accuracy: 0.65

# ============================================================================
# Hardware & Performance
# ============================================================================

hardware:
  # Device
  device: "cuda"                     # cuda, cpu, mps (Apple Silicon)
  device_map: "auto"                 # auto, balanced, sequential

  # Multi-GPU
  use_ddp: false                     # DistributedDataParallel
  use_fsdp: false                    # FullyShardedDataParallel
  num_gpus: 1

  # Memory optimization
  optim: "paged_adamw_32bit"         # For QLoRA
  max_memory_mb: null                # null = auto

  # Performance
  dataloader_num_workers: 4
  dataloader_pin_memory: true
  torch_compile: false               # Experimental: PyTorch 2.0 compilation

# ============================================================================
# Monitoring & Logging
# ============================================================================

monitoring:
  # Weights & Biases
  use_wandb: false
  wandb_project: "stock-agent-sft"
  wandb_entity: null
  wandb_run_name: null               # Auto-generated if null

  # TensorBoard
  use_tensorboard: true
  tensorboard_log_dir: "logs/tensorboard"

  # MLflow
  use_mlflow: false
  mlflow_tracking_uri: null
  mlflow_experiment_name: "stock-agent-sft"

  # Custom logging
  log_file: "logs/sft_training.log"
  log_level: "INFO"                  # DEBUG, INFO, WARNING, ERROR

# ============================================================================
# Testing & Debugging
# ============================================================================

debug:
  # Debug mode
  debug_mode: false
  max_train_samples: null            # Limit training samples for debugging
  max_eval_samples: null

  # Overfit test (sanity check)
  overfit_test: false
  overfit_batches: 10

  # Profiling
  profile_memory: false
  profile_time: false

# ============================================================================
# Presets
# ============================================================================

presets:
  # Quick test (for development)
  quick_test:
    num_epochs: 1
    max_train_samples: 100
    max_eval_samples: 50
    save_steps: 50
    eval_steps: 50
    logging_steps: 5

  # Production training
  production:
    num_epochs: 3
    per_device_train_batch_size: 4
    gradient_accumulation_steps: 8   # Larger effective batch
    save_total_limit: 5
    early_stopping_patience: 5

  # High quality (more epochs, better hyperparams)
  high_quality:
    num_epochs: 5
    learning_rate: 1.0e-4
    warmup_ratio: 0.05
    save_total_limit: 10
    early_stopping_patience: 10

# ============================================================================
# Regression Guards Configuration
# ============================================================================

regression_guards:
  # Default tolerance for all metrics (percentage)
  default_tolerance_pct: 2.0

  # Metric-specific tolerances
  loss_tolerance_pct: 3.0           # Allow 3% increase in loss
  accuracy_tolerance_pct: 2.0       # Allow 2% decrease in accuracy
  f1_tolerance_pct: 2.0             # Allow 2% decrease in F1
  perplexity_tolerance_pct: 5.0     # Allow 5% increase in perplexity (non-critical)

  # Custom metric policies
  custom_policies: []

  # Override settings
  allow_override_single_critical: true    # Allow override if only 1 critical failure
  require_override_reason: true           # Require reason for overrides
  min_override_reason_length: 10          # Minimum characters for override reason
